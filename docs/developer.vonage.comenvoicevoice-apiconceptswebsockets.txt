Use Cases
Documentation
SDKs & Tools
Community
Blog
API Dashboard
Vonage.com
Pricing
Support
English
中文
日本語
My profile
My dashboard
Log out
Voice
Voice API
Overview
Concepts
Call Flow
Call Control Objects
Numbers
Endpoints
Text to Speech
Customizing Spoken Text
Speech to Text
DTMF
Call Recording
Web Sockets
Contact Center Intelligence
Fraud Prevention
Guides
Code Snippets
Tutorials
Voice Inspector (Beta)
NCCO Reference
Webhook Reference
API Reference
SIP
Web Sockets

This guide introduces you to WebSockets and how and why you might want to use them in your Vonage Voice API applications.

For sample applications and AI connectors, see further reading.

What is a WebSocket?

WebSockets is a computer communications protocol that enables two-way communication over a single, persistent TCP connection without the overhead of the HTTP request/response model.

Using Vonage’s Voice API, you can connect phone calls to WebSocket endpoints. This means that any application that hosts a WebSocket server can be a participant in a Vonage voice conversation. It can receive raw audio from and play audio into the call in real time.

This enables some really innovative use cases, such as:

Recording, transcribing or otherwise analyzing calls using third party solutions. For example: performing sentiment analysis in call centers to determine customer satisfaction.
Automating calls with bots to perform tasks such as food ordering or requesting information from field experts.
Including artificial intelligence engines in conference calls to enable better decision making.
Working with WebSockets

The WebSocket is an endpoint in the same way that a phone or SIP address is. This means it is a participant in your call and not a passive monitor like a recording. If you connect a WebSocket to a conference call, or a third-party in a 1-1 call, the audio it receives is a mix of all the audio in the call. It is not possible to receive a single leg of the conversation via the WebSocket.

The Vonage Voice API acts as the client when establishing the WebSocket connection. As the application developer you need to make a compatible server available to:

Return an NCCO instructing Vonage to connect to your WebSocket endpoint
Accept this WebSocket connection
Handle JSON text-based protocol messages
Handle mixed call audio binary messages
Connecting to a WebSocket

To instruct Vonage to connect to a WebSocket your application server must return an NCCO when requested from your Vonage Application's answer_url. In order to do this the NCCO must contain a connect action with an endpoint.type of websocket. For example:

[
    {
       "action": "connect",
       "endpoint": [
           {
                "type": "websocket",
                "uri": "wss://example.com/socket",
                "content-type": "audio/l16;rate=16000",
                "headers": {
                    "language": "en-GB",                    
                    "caller-id": "447700900123"
                }
           }
       ]
     }
]

Copy

The specific data fields for webhooks are the following:

Field	Example	Description
uri	wss://example.com/socket	The endpoint of your WebSocket server that Vonage will connect to
content-type	audio/l16;rate=16000	A string representing the audio sampling rate, either audio/l16;rate=16000 or audio/l16;rate=8000. Most real-time transcription services work best with audio at 8kHz.
headers	{ 'language': 'en-GB', 'caller-id': '447700900123' }	An object of key/value pairs with additional optional properties to send to your Websocket server, with a maximum length of 512 bytes.

You can find all the data fields for an NCCO at the NCCO Reference Guide.

Handling incoming WebSocket messages
First message

The initial message sent on an established WebSocket connection will be text-based and contain a JSON payload, it will have the event field set to websocket:connected and detail the audio format in content-type, along with any other metadata that you have put in the headers property of the WebSocket endpoint in your NCCO connect action. The headers property is not present on the JSON payload so the properties are at the top-level of the JSON. For example:

{
    "event":"websocket:connected",
    "content-type":"audio/l16;rate=16000",
    "prop1": "value1",
    "prop2": "value2"
}

Copy

Consider the following connect action example:

[
    {
       "action": "connect",
       "endpoint": [
           {
              "type": "websocket",
              "uri": "wss://example.com/socket",
              "content-type": "audio/l16;rate=16000", 
              "headers": {
                 "language": "en-GB",
                 "caller-id": "447700900123"
              }
           }
       ]
     }
]

Copy

This results in the following JSON in the first message on the WebSocket:

{
    "event":"websocket:connected",
    "content-type":"audio/l16;rate=16000",
    "language": "en-GB",
    "caller-id": "447700900123"
}

Copy

After the initial text message subsequent messages on the WebSocket can be text or binary.

Binary audio messages

Messages that are binary represent the audio of the call. The audio codec presently supported on the WebSocket interface is Linear PCM 16-bit, with either a 8kHz or a 16kHz sample rate, and a 20ms frame size.

To choose the sampling rate set the Content-Type property to audio/l16;rate=16000 or audio/l16;rate=8000 depending on if you need the data at 16kHz or 8kHz. Most real-time transcription services work best with audio at 8kHz.

Each message will be a 20ms sample of the audio from the call. If you choose the 8kHz rate each message will be 320 bytes. Choosing the 16kHz rate will result in each message being 640 bytes. This is summarized in the following table:

Sampling rate (samples per second)	Number of samples in 20ms	Bytes per message
8000	160	160 x 2 = 320
16000	320	320 x 2 = 640
JSON DTMF messages

If any party on the call connected to the websocket sends a DTMF tone this will trigger an event on the websocket, this event is a text message with a JSON payload, it will be interleaved between the audio frames and have the following format:

{"event":"websocket:dtmf","digit":"5","duration":260}

Copy

You will receive one event for each keypress and each event will contain only one digit.

event allows you to identify it as a DTMF event
digit contains the digit pressed 0-9 * or #
duration is the duration the key was pressed for in milliseconds, on most digital phone systems this will be a fixed length.
Writing audio to the WebSocket

You can send audio back into the call by writing binary messages to the WebSocket. The audio must be in the same format as described in the previous section. It is important that each message is 320 or 640 bytes (depending on sample rate) and contains 20ms of audio.

You can send the messages at a faster than real-time rate and they will be buffered by our API platform for later playback. So for example, you can send an entire file to the socket in one write, providing the 320/640 byte per message restriction is observed. Vonage will only buffer 1024 messages which should be enough for around 20 seconds of audio, if your file is longer than this you should implement a delay of 18-19ms between each message, or consider using the REST API to play an audio file.

WebSocket Event Callbacks

Event data is sent to the eventURL as with all voice applications. This is a POST request by default, but you can specify the request type in the eventMethod parameter of the connect action.

Event callbacks are documented in the Webhook Reference Guide. In the guide you can find all the types of webhooks and the parameters each webhook sends as part of its payload.

Within WebSockets particularly, you can also set custom metadata in your event callback with the headers parameter.

Fallback Options

A common use case for custom metadata is providing useful information for fallback options. For example, you way want to include the original from number in the fallback event as caller-id. To do that, use the headers parameter in the connect action as described above. This information is then included in the event webhook payload as follows:

{
  "from": "442079460000",
  "to": "wss://example.com/socket",
  "uuid": "aaaaaaaa-bbbb-cccc-dddd-0123456789ab",
  "conversation_uuid": "CON-aaaaaaaa-bbbb-cccc-dddd-0123456789ab",
  "status": "disconnected",
  "timestamp": "2020-03-31T12:00:00.000Z",
  "headers": {
    "caller-id": "447700900123"
  }
}

Copy

You can also be notified via an event when a connection to a WebSocket cannot be established or if the application terminates the WebSocket connection for any reason.

Connection cannot be established

To receive this event, you must include the eventType: synchronous in your connect action:

[
  {
    "action": "connect",
    "eventType": "synchronous",
    "eventUrl": [
      "https://example.com/events"
    ],
    "from": "447700900000",
    "endpoint": [
      {
        "type": "websocket",
        "uri": "wss://example.com/socket",
        "content-type": "audio/l16;rate=16000",
        "headers": {
            "caller-id": "447700900123"
        }        
      }
    ]
  }
]

Copy

You can then return a new NCCO in the response with the required fallback actions. For example, if you cannot establish a connection, you might want to play a message to the caller or transfer the call. In the event of a connection failure, the event status will be one of failed or unanswered. For example:

{
  "from": "442079460000",
  "to": "wss://example.com/socket",
  "uuid": "aaaaaaaa-bbbb-cccc-dddd-0123456789ab",
  "conversation_uuid": "CON-aaaaaaaa-bbbb-cccc-dddd-0123456789ab",
  "status": "unanswered",
  "timestamp": "2020-03-31T12:00:00.000Z",
  "headers": {
    "caller-id": "447700900123"
  }  
}

Copy

You can return a new NCCO in your webhook response to handle the failed connection attempt. If you do not return an NCCO, the next action in the original NCCO will be processed. If there are no further actions in the original NCCO, the call will complete.

Websocket disconnected

If the connection is dropped by your application, you will receive an event on your eventUrl webhook with a status of disconnected:

{
  "from": "442079460000",
  "to": "wss://example.com/socket",
  "uuid": "aaaaaaaa-bbbb-cccc-dddd-0123456789ab",
  "conversation_uuid": "CON-aaaaaaaa-bbbb-cccc-dddd-0123456789ab",
  "status": "disconnected",
  "timestamp": "2020-03-31T12:00:00.000Z",
  "headers": {
    "caller-id": "447700900123"
  }
}

Copy

When you receive a disconnected event, you can commence your fallback strategy by providing a new NCCO in the response.

However, the disconnected event gets raised both when the disconnection was unintentional (due to some problem) or you intentionally disconnected the websocket (as part of your business logic).

Ideally, you want to fallback only when the disconnect is unintentional, so a better approach than closing the connection is to explicitly terminate the call leg via an API request:

PUT https://api.nexmo.com/v1/calls/aaaaaaaa-bbbb-cccc-dddd-0123456789ab

{
  "action": "hangup"
}

Copy

This method does not raise a disconnected event. Therefore, if you do receive a disconnected event you can reliably assume that it is an unintentional disconnection and fallback appropriately. You can also use the Fallback URL webhook with this approach.

Further reading

Use the following resources to help you make the most of WebSockets in your Voice API applications:

Getting started with WebSockets Webinar
Tutorial: Create a WebSocket echo server
Node
Python
Demo apps:

Browser audio demo: Send conference call audio to a web browser using WebSockets and the browser Web Audio API (Python)

WebSocket recorder demo: Receive binary from a WebSocket, store it in a file and then convert it to WAV format.

Node
Python
.NET

Audio socket framework: A useful starting point for interfacing between Vonage and an AI bot platform

Socket phone: Connect a Vonage WebSocket call to your local machine

AI Connectors:
Voice Bots
Amazon Lex, see also sample app and tutorial
Google Dialogflow, see also sample app
Real-time transcription
Amazon Transcribe
Google Speech-to-Text
IBM Watson
Microsoft Azure
Sentiment Analysis
Amazon Comprehend
IBM Watson
Blog articles:
Processing Voice Calls With Amazon Transcribe & Comprehend
Connecting Voice Calls to an Amazon Lex Bot
How to Make and Receive Phone Calls with Nuxt.js
Creating a WebSocket Server with the Spark Framework
Creating a WebSocket Server with Spring Boot
Real-time Call Transcription Using IBM Watson and Python
Feedback